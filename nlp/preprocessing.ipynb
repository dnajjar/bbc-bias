{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b344cf28-ce52-494d-bba1-d95d2047e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "# import multiprocessing as mp\n",
    "\n",
    "# NLTK imports\n",
    "import nltk\n",
    "\n",
    "nltk.data.path.append('../nltk_data/')\n",
    "import string\n",
    "from nltk import collocations\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b96f318-bc52-4e7d-b879-e05fe29360f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scraped data\n",
    "df = pd.read_csv('../data/summary_20231127.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df[df['date'] > '2023-10-7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a70d28a9-45df-4b5f-9ceb-5dc22ae2e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "import re\n",
    "\n",
    "rx = r\"\\.(?!(?<=\\d\\.)\\d)(?=\\S)\"\n",
    "\n",
    "# fix some of the full stop formatting in the original files\n",
    "df['text'] = df['text'].apply(ast.literal_eval)\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(rx, \". \", ' '.join([s for s in x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7ad495e-ed71-439e-8d17-7035b35dc31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_article_files(row):\n",
    "    text = \"\"\n",
    "    \n",
    "    _id = row['id']\n",
    "    title = row['title']\n",
    "    date = row['date'].date()\n",
    "    content = row['text']\n",
    "    \n",
    "    # Assemble as part of large text block\n",
    "    text += \" F-N-S-T-A-R-T. \"\n",
    "    text += str(_id)\n",
    "    text += \" F-N-E-N-D. \"\n",
    "    text += \" D-A-T-E-S-T-A-R-T. \"\n",
    "    text += date.strftime(format=\"%Y-%m-%d\")\n",
    "    text += \" D-A-T-E-E-N-D. \"\n",
    "    text += \" T-I-T-L-E-S-T-A-R-T. \"\n",
    "    text += title\n",
    "    text += \" T-I-T-L-E-E-N-D. \"\n",
    "    text += \" T-E-X-T-S-T-A-R-T. \"\n",
    "    text += content\n",
    "    text += \" T-E-X-T-E-N-D. \"\n",
    "    \n",
    "    # Save current text chunk\n",
    "    article_filename = \"articles/article_\" + str(_id) + \".txt\"\n",
    "    results_filename = \"results/article_\"+str(_id)+\".txt.json\"\n",
    "    \n",
    "    with open(article_filename, 'w') as f:\n",
    "        f.write(text)\n",
    "        \n",
    "    #create dataframe which points to expected files\n",
    "    row['article_file'] = article_filename\n",
    "    row['results_file'] = results_filename\n",
    "    \n",
    "    return row\n",
    "\n",
    "# generate article file in the format required for stanford nlp\n",
    "df = df.apply(generate_article_files,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e100fad-d7c3-46cc-b769-cca696ff650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/summary_20231127.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64c1fc12-f839-4e87-a123-bc2a6f0cc277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all-texts.txt which is going to be used for stanford nlp\n",
    "import glob\n",
    "all_articles = [os.path.abspath(f) for f in glob.glob(\"./articles/*.txt\")]\n",
    "\n",
    "with open(\"./all-files.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(all_articles))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
